---
layout: post
toc: true
title: "M5 - Forecasting - Part-I"
categories: portfolio
tags: [markdown, forecasting, html, EDA, Plotly]
---

# An End-to-End Machine Learning Web App

Since summer, I have been learning a lot about computer vision from the basics as I wanted to apply those skills more in industrial automation. At the same time, many blogs and articles started screaming to create an end-to-end machine learning model to understand the engineering behind the usefulness of the machine learning model. 

So, when I came across this [applied-ml github](https://github.com/eugeneyan/applied-ml#computer-vision) by Eugene Yan, this [airbnb paper](https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e) caught my eye and I was excited to apply to learn and learn new engineering skills by following this article.

This article was pretty in detail, an almost step by step method one can follow to create a business machine learning model. As I was learning new aspects of machine learning engineering, I wanted to follow the article step by step and replicate it and achieve similar results.  

## BUSINESS CASE:
#### Purpose of Project and Business case of this machine learning model:
 * The purpose of this project is to build an object detection model and be able to create an interface to use the model. Overall, I wanted to learn the skills required to build an end-to-end machine learning app. 
 * This model can help in finding the essential amenities in a house from the photos taken by the owner and adds them to the listing automatically, thereby decreasing the errors of a chance of missing out of humans. This model could help both the lister, consumer, and Airbnb to have the right list of amenities listed on the app and also become a significant factor in determining the amount of charge a listing be listed.

## Steps Involved:
  1. Gathering Data
  2. Preprocessing of the Data
  3. Modelling
  4. Hyper-parameter Tuning
  4. Testing and Inference
  5. Develop API
  6. Deploy the app using API


### Data Collection 
The most important part of this model is building a dataset of images of house amenities. As mentioned in the article, Airbnb took majority images from internal databse and remaining images from openimages dataset. 
But before building the dataset, they had to decide the taxonomy, amenity labels. The taxonomy here should help the specific business needs. After reviewing, they came with 40 amenity classes like kitchen, bathroom, and bedroom, such as gas stove, oven, refrigerator, bathtub, shower, towel, bed, pillow, etc. 
Being a business, they could build a huge image dataset from all sources. But being a hobby project and individual, we don't have that luxury. So the next best thing is to use the available image datasets. As I was going through the article, I observed that the Airbnb engineering team started modelling with the images from Open Image Dataset. So I thought why not me.
I went through the classes in the openimages Dataset and came with 30 house amenities classes that could be useful for my model. 
```
names: ['Bathtub', 'Bed', 'Billiard table', 'Ceiling fan', 'Coffeemaker', 'Couch', 'Countertop', 'Dishwasher', 'Fireplace', 'Fountain', 
        'Gas stove', 'Jacuzzi', 'Kitchen & dining room table', 'Microwave oven', 'Mirror', 'Oven', 'Pillow', 'Porch', 'Refrigerator', 'Shower', 
        'Sink', 'Sofa bed', 'Stairs',  'Swimming pool', 'Television', 'Toilet', 'Towel', 'Tree house', 'Washing machine', 'Wine rack'] 
```
From Opem Images dataset, I downloaded around 36k images for training, 1000 images for validation and 2500 images for testing purpose.
Now for object detection, its not just images but we also need labels. Luckily the open image dataset comes with annotation labels. I downloaded the annotations file and classes file to build the label database. 
Now creating the annotate image dataset is important part of modelling as we have to build the dataset according to the model we have selected unless we are building the model from scratch, which I am doing here.
Before creating annotation dataset, I have decide on the model I am going to use. So I started reading about all the object detection model that have been created till now. R-CNN, Fast R-CNN, YOLO, EfficientDet, Detectron2, etc. As I reading more and more, I wanted to use Detectron2 as it was the most advance detection model and also it provides the most flexibility in selecting the model from its model_zoo. But, I came across another article, where Daniel Bourke replicated the same airbnb article using Detectron2. Now I thought my project is over as already he has build and replicated it and if I do it the same I might not learning and doing any thing different. Then suddenly YOLOv5 was released and the results were also astonishing. It was using a Resnet model under and the hyper-parameters were not the flexible to change. But still I didn't to replicate the same Mr.Bourke did. So I started decide to use YOLOv5 framework to build my model. 

For Yolov5, I need the annotation database as a txt file containing the box dimensions and classes for each image. A txt file can contain many classes. This dataset is built using ```prepare.py``` which obtains modules from preprocessing and mungedata which helps in getting images ids, format annotations and create the annotations box data.

It took me around 30min to one hour to create the dataset. 







